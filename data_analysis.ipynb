{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('vae': conda)",
   "metadata": {
    "interpreter": {
     "hash": "eb5bc1cfb9acb33b1e6c4f7077eeee3518340c293d678b13d452bea5d718ad28"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/janek/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.preprocess import preprocess_IMDB_sentence\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from convokit import Corpus, download, FightingWords, Utterance, Speaker\n",
    "from collections import Counter\n",
    "from torchtext.vocab import GloVe\n",
    "from utils.corpus import get_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_from_source(source, field, n):\n",
    "    df, _  = get_corpus(source, text_field=field, split_sentences=True, punct=False, to_ascii=True,\n",
    "                min_len=3, max_len=15,  test_size=0.0001, subsample_rows=n, save=False)\n",
    "    speaker = Speaker(meta={'name': source})\n",
    "    utts = [Utterance(id=f'{source}{i}', text=' '.join(t), speaker=speaker) for i, t in enumerate(df.utterance) ]\n",
    "    corp = Corpus(utterances=utts)\n",
    "    return df, corp\n",
    "\n",
    "def compare_corpora(c1, c2, n1, n2):\n",
    "    print(n1)\n",
    "    c1.print_summary_stats()\n",
    "    print(c1.get_utterances_dataframe().text.map(lambda x: x.split()).map(len).describe())\n",
    "    print('\\n'.join(c1.random_utterance().text for _ in range(10)))\n",
    "    print('\\n')\n",
    "    print(n2)\n",
    "    c2.print_summary_stats()\n",
    "    print(c2.get_utterances_dataframe().text.map(lambda x: x.split()).map(len).describe())\n",
    "    print('\\n'.join(c2.random_utterance().text for _ in range(10)))\n",
    "    ids1 = set(c1.get_utterance_ids())\n",
    "    corp = c1.merge(c2)\n",
    "    fw = FightingWords(ngram_range=(1,1))\n",
    "    fw.fit(corp, class1_func=lambda utt: utt.id in ids1, \n",
    "                 class2_func=lambda utt: utt.id not in ids1)\n",
    "    print(fw.summarize(corp, plot=False, class1_name=n1,\n",
    "                                          class2_name=n2))\n",
    "    return fw\n",
    "    \n",
    "def run_comparison(source1, field1, source2, field2, n=1000):\n",
    "    print('loading ', source1)\n",
    "    df1, c1 = corpus_from_source(source1, field1, n)\n",
    "    print('loading ', source2)\n",
    "    df2, c2 = corpus_from_source(source2, field2, n)\n",
    "    fw = compare_corpora(c1, c2, source1, source2)\n",
    "\n",
    "def word_freqs(data, voc, n=1000):\n",
    "    return Counter(w if w in voc else 'unk' for s in data.iloc[:n] for w in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb = pd.read_csv('data_options/IMDB Dataset.csv')\n",
    "# food = pd.read_csv('data_options/Reviews.csv')\n",
    "# movies = pd.read_csv('data_options/movies_metadata.csv')\n",
    "# tmbd = pd.read_csv('data_options/tmdb_5000_movies.csv')\n",
    "# hotels = pd.read_csv('data_options/tripadvisor_hotel_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data_options/google-10000-english-usa.txt', 'r') as fh:\n",
    "#     vocab1 = set(t.strip() for t in fh.readlines())\n",
    "# g = GloVe('6B',dim=50)\n",
    "# v = set(g.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading  friends-corpus\n",
      "Downloading dataset...\n",
      "Dataset already exists at /Users/janek/.convokit/downloads/friends-corpus\n",
      "Cleaning\n",
      "10024\n",
      "2\n",
      "loading  IMDB Dataset.csv\n",
      "Loading dataset from csv...\n",
      "Cleaning\n",
      "32757\n",
      "4\n",
      "friends-corpus\n",
      "Number of Speakers: 1\n",
      "Number of Utterances: 10024\n",
      "Number of Conversations: 1\n",
      "count    10024.000000\n",
      "mean         6.928372\n",
      "std          3.260859\n",
      "min          3.000000\n",
      "25%          4.000000\n",
      "50%          6.000000\n",
      "75%          9.000000\n",
      "max         15.000000\n",
      "Name: text, dtype: float64\n",
      "oh so did i\n",
      "oh will you do the top of the cabinets\n",
      "hey rach did you make your money\n",
      "do you know how hard it is to meet a guy like that\n",
      "you took your eggs and you left\n",
      "how about a little of that smoked turkey\n",
      "i get it\n",
      "oh no no never say that\n",
      "do n't be\n",
      "you are going to make a joke about my special present\n",
      "\n",
      "\n",
      "IMDB Dataset.csv\n",
      "Number of Speakers: 1\n",
      "Number of Utterances: 32757\n",
      "Number of Conversations: 1\n",
      "count    32757.000000\n",
      "mean         9.623165\n",
      "std          3.527539\n",
      "min          3.000000\n",
      "25%          7.000000\n",
      "50%         10.000000\n",
      "75%         13.000000\n",
      "max         15.000000\n",
      "Name: text, dtype: float64\n",
      "jeff lowell has written directed 'over her dead body ' poorly\n",
      "emotive powerful very moving horrific and heart breaking\n",
      "to call this anything at all would be an insult to everything else\n",
      "title brazil jack o demonio do halloween jack o demon of the halloween\n",
      "the story is taken from great movies like texas chainsaw massacre and hills have eyes\n",
      "2 out of 10\n",
      "the dialog is exquisite\n",
      "takashi miike 's masters of horror episode is boring uninspiring and pointless\n",
      "the episode is played for laughs but it also can be pretty intense at times\n",
      "theresa russell might seem too glamorous as ma but she has some very good moments\n",
      "\u001b[91mWARNING: \u001b[0mMultiple values found for Speaker(id: None, vectors: [], meta: {'name': 'IMDB Dataset.csv'}) for metadata key: 'name'. Taking the latest one found\n",
      "Initializing default CountVectorizer with ngram_range (1, 1)... Done.\n",
      "class1_func returned 10024 valid corpus components. class2_func returned 32757 valid corpus components.\n",
      "Vocab size is 2735\n",
      "Comparing language...\n",
      "ngram zscores computed.\n",
      "         z-score             class\n",
      "ngram                             \n",
      "the   -32.662519  IMDB Dataset.csv\n",
      "of    -21.764450  IMDB Dataset.csv\n",
      "this  -21.187683  IMDB Dataset.csv\n",
      "is    -19.722334  IMDB Dataset.csv\n",
      "and   -17.998561  IMDB Dataset.csv\n",
      "...          ...               ...\n",
      "re     29.856557    friends-corpus\n",
      "do     30.676497    friends-corpus\n",
      "know   31.750104    friends-corpus\n",
      "oh     36.083310    friends-corpus\n",
      "you    68.337775    friends-corpus\n",
      "\n",
      "[2735 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "run_comparison('friends-corpus', 'text', 'IMDB Dataset.csv', 'review', n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset already exists at /Users/janek/.convokit/downloads/friends-corpus\n"
     ]
    }
   ],
   "source": [
    "friends = Corpus(filename=download(\"friends-corpus\"))\n",
    "# supreme = Corpus(filename=download(\"supreme-corpus\"))\n",
    "# # parliament = Corpus(filename=download(\"parliament-corpus\"))\n",
    "# movie = Corpus(filename=download(\"movie-corpus\"))\n",
    "# diplomacy = Corpus(filename=download(\"diplomacy-corpus\")) # game, written\n",
    "# switchboard = Corpus(filename=download(\"switchboard-corpus\")) # conversational, from spoken\n",
    "# reddit = Corpus(filename=download('reddit-corpus-small'))\n",
    "# tennis = Corpus(filename=download('tennis-corpus'))"
   ]
  }
 ]
}